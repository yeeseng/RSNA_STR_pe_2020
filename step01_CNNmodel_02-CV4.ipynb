{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import albumentations as albu\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "#from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, classification_report, roc_curve, average_precision_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from pydicom import dcmread\n",
    "import glob\n",
    "import pickle\n",
    "import scipy\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from datetime import datetime\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF = pd.read_csv('forTrainingDataFold.csv', dtype={'StudyInstanceUID': 'string', 'SeriesInstanceUID':'string', 'SOPInstanceUID':'string'})\n",
    "dataDF = dataDF.set_index('SOPInstanceUID')\n",
    "dataDF = dataDF.drop(['StudyInstanceUID','SeriesInstanceUID','rv_lv_ratio_lt_1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pe_present_on_image</th>\n",
       "      <th>acute</th>\n",
       "      <th>chronic</th>\n",
       "      <th>leftsided_pe</th>\n",
       "      <th>rightsided_pe</th>\n",
       "      <th>central_pe</th>\n",
       "      <th>rv_lv_ratio_gte_1</th>\n",
       "      <th>qa_motion</th>\n",
       "      <th>qa_contrast</th>\n",
       "      <th>flow_artifact</th>\n",
       "      <th>true_filling_defect_not_pe</th>\n",
       "      <th>negative_exam_for_pe</th>\n",
       "      <th>chronic_pe</th>\n",
       "      <th>acute_and_chronic_pe</th>\n",
       "      <th>indeterminate</th>\n",
       "      <th>img_pos</th>\n",
       "      <th>patient_position</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOPInstanceUID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c0f3cb036d06</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-234.5</td>\n",
       "      <td>HFS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f57ffd3883b6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-252.5</td>\n",
       "      <td>HFS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41220fda34a3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-432.5</td>\n",
       "      <td>HFS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13b685b4b14f</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-434.5</td>\n",
       "      <td>HFS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be0b7524ffb4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-436.5</td>\n",
       "      <td>HFS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pe_present_on_image  acute  chronic  leftsided_pe  \\\n",
       "SOPInstanceUID                                                      \n",
       "c0f3cb036d06                      0      1        0             1   \n",
       "f57ffd3883b6                      0      1        0             1   \n",
       "41220fda34a3                      0      1        0             1   \n",
       "13b685b4b14f                      0      1        0             1   \n",
       "be0b7524ffb4                      0      1        0             1   \n",
       "\n",
       "                rightsided_pe  central_pe  rv_lv_ratio_gte_1  qa_motion  \\\n",
       "SOPInstanceUID                                                            \n",
       "c0f3cb036d06                1           0                  0          0   \n",
       "f57ffd3883b6                1           0                  0          0   \n",
       "41220fda34a3                1           0                  0          0   \n",
       "13b685b4b14f                1           0                  0          0   \n",
       "be0b7524ffb4                1           0                  0          0   \n",
       "\n",
       "                qa_contrast  flow_artifact  true_filling_defect_not_pe  \\\n",
       "SOPInstanceUID                                                           \n",
       "c0f3cb036d06              0              0                           0   \n",
       "f57ffd3883b6              0              0                           0   \n",
       "41220fda34a3              0              0                           0   \n",
       "13b685b4b14f              0              0                           0   \n",
       "be0b7524ffb4              0              0                           0   \n",
       "\n",
       "                negative_exam_for_pe  chronic_pe  acute_and_chronic_pe  \\\n",
       "SOPInstanceUID                                                           \n",
       "c0f3cb036d06                       0           0                     0   \n",
       "f57ffd3883b6                       0           0                     0   \n",
       "41220fda34a3                       0           0                     0   \n",
       "13b685b4b14f                       0           0                     0   \n",
       "be0b7524ffb4                       0           0                     0   \n",
       "\n",
       "                indeterminate  img_pos patient_position  fold  \n",
       "SOPInstanceUID                                                 \n",
       "c0f3cb036d06                0   -234.5              HFS     3  \n",
       "f57ffd3883b6                0   -252.5              HFS     3  \n",
       "41220fda34a3                0   -432.5              HFS     3  \n",
       "13b685b4b14f                0   -434.5              HFS     3  \n",
       "be0b7524ffb4                0   -436.5              HFS     3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct path mapping dict for jpg files \n",
    "listOfDCMfiles = glob.glob('data/train/*/*/*.dcm')\n",
    "\n",
    "imageID2pathDict = {}\n",
    "\n",
    "for eachPath in listOfDCMfiles:\n",
    "    imageID = eachPath.split('/')[-1][:-4]\n",
    "    imageID2pathDict[imageID] = eachPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training labels\n",
    "gtLabelDict = pickle.load(open('data/CNNtrainingLabel.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "sampleImageID = list(gtLabelDict.keys())[5]\n",
    "print(gtLabelDict[sampleImageID])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "        albu.ShiftScaleRotate(scale_limit=0.05, rotate_limit=30, shift_limit=0.05, p=1, border_mode=0),\n",
    "        albu.IAAAdditiveGaussianNoise(p=0.1),\n",
    "        albu.IAAPerspective(p=0.2),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.CLAHE(p=1),\n",
    "                albu.RandomBrightness(p=1),\n",
    "                albu.RandomGamma(p=1),\n",
    "            ],\n",
    "            p=0.3,\n",
    "        ),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.IAASharpen(p=1),\n",
    "                albu.Blur(blur_limit=3, p=1),\n",
    "                albu.MotionBlur(blur_limit=3, p=1),\n",
    "            ],\n",
    "            p=0.3,\n",
    "        ),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.RandomContrast(p=1),\n",
    "                albu.HueSaturationValue(p=1),\n",
    "            ],\n",
    "            p=0.3,\n",
    "        ),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    '''\n",
    "    test_transform = [\n",
    "        albu.PadIfNeeded(384, 480)\n",
    "    ]\n",
    "    '''\n",
    "    return albu.Compose(test_transform)\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(img, WL=50, WW=350):\n",
    "    upper, lower = WL+WW//2, WL-WW//2\n",
    "    X = np.clip(img.copy(), lower, upper)\n",
    "    X = X - np.min(X)\n",
    "    X = X / np.max(X)\n",
    "    X = (X*255.0).astype('uint8')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(BaseDataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            dataframe=None, \n",
    "            augmentation=None,\n",
    "            transform=None,\n",
    "            dirPath=None,\n",
    "    ):\n",
    "        self.dataframe = dataframe\n",
    "        self.ids = self.dataframe.index.values.tolist()     \n",
    "        self.augmentation = augmentation\n",
    "        self.transform=transform\n",
    "        self.dirPath = dirPath\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        thisID = self.ids[i]\n",
    "        \n",
    "        #jpgPath = imageID2pathDict[thisID]\n",
    "        #image = cv2.imread(jpgPath)\n",
    "        \n",
    "        dcmPath = imageID2pathDict[thisID]\n",
    "        dcm_data = dcmread(dcmPath)\n",
    "        image = dcm_data.pixel_array * int(dcm_data.RescaleSlope) + int(dcm_data.RescaleIntercept)\n",
    "        image = np.stack([window(image, WL=-600, WW=1500),\n",
    "                          window(image, WL=40, WW=400),\n",
    "                          window(image, WL=100, WW=700)], 2)\n",
    "        \n",
    "        target = gtLabelDict[thisID]    \n",
    "        target = target.astype(np.float32)\n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image)\n",
    "            image = sample['image']\n",
    "        \n",
    "        '''\n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image)\n",
    "            image = sample['image']\n",
    "        '''\n",
    "        \n",
    "        image = image.astype(np.float32)\n",
    "        #image = np.rollaxis(image, -1, 0)  \n",
    "        #image = image.transpose((2, 0, 1))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50_model():\n",
    "    myModel = models.resnet50(pretrained=True)\n",
    "    num_ftrs = myModel.fc.in_features\n",
    "    myModel.fc = nn.Sequential(\n",
    "        nn.Linear(num_ftrs, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p = 0.2),\n",
    "        nn.Linear(256, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 8),\n",
    "        )\n",
    "    return myModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom weighted loss function\n",
    "class customWeightedBCEwithLogits(nn.Module):\n",
    "    def __init__(self, PE_pos_weight = 3.0, other_pos_weight = [30.0, 30.0, 3.0, 3.0, 3.0, 1.2, 0.5]):\n",
    "        super(customWeightedBCEwithLogits, self).__init__()\n",
    "        self.image_PE_PosWeight = torch.tensor(PE_pos_weight, requires_grad=False).cuda()\n",
    "        self.otherLabels_PosWeight = torch.tensor(other_pos_weight, requires_grad=False).cuda()\n",
    "        self.criterion1 = nn.BCEWithLogitsLoss(pos_weight=self.image_PE_PosWeight)\n",
    "        self.criterion2 = nn.BCEWithLogitsLoss(pos_weight=self.otherLabels_PosWeight)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        loss1 = self.criterion1(inputs[:,0:1], targets[:,0:1])\n",
    "        loss2 = self.criterion2(inputs[:,1:], targets[:,1:])\n",
    "        return loss1+loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_loader, valid_loader):\n",
    "    # Train one epoch\n",
    "    train_total = train_correct = train_cost = 0\n",
    "    model.train()\n",
    "    for x, y in tqdm(train_loader):\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        z = model(x)\n",
    "        train_total += y.size(0)\n",
    "        train_correct += ((torch.sigmoid(z[:,0])>0.5) == (y[:,0]>0.5)).sum().item()\n",
    "        loss = customLoss(z, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_cost += loss.item()\n",
    "    return train_cost/train_total, train_correct/train_total\n",
    "\n",
    "def valid_loop(model, train_loader, valid_loader):\n",
    "    # Evaluate on validation  data \n",
    "    val_total = val_correct = val_cost = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in tqdm(valid_loader):\n",
    "            x_val = x_val.cuda()\n",
    "            y_val = y_val.cuda()\n",
    "            z = model(x_val)\n",
    "            val_total += y_val.size(0)\n",
    "            val_correct += ((torch.sigmoid(z[:,0])>0.5) == (y_val[:,0]>0.5)).sum().item()\n",
    "            loss = customLoss(z, y_val)\n",
    "            val_cost += loss.item()\n",
    "    return val_cost/val_total, val_correct/val_total\n",
    "\n",
    "def main_loop(n_epochs, model, train_loader, valid_loader):\n",
    "    for epoch in range(n_epochs):\n",
    "        print('epoch ' + str(epoch) + ':')\n",
    "        train_avgCost, train_acc = train_loop(model, train_loader, valid_loader)\n",
    "        val_avgCost, val_acc = valid_loop(model, train_loader, valid_loader)\n",
    "        print('train_cost: %.4f, train_acc: %.4f, val_cost: %.4f, val_acc: %.4f'\\\n",
    "              % (train_avgCost, train_acc, val_avgCost, val_acc))\n",
    "        now = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "        modelPath = 'models/CNNmodel/CNNmodel_01_epoch' + str(epoch) + '_' + now +'.pth'\n",
    "        print('saving: ',modelPath)\n",
    "        torch.save(model, modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = resnet50_model()\n",
    "myModel = myModel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train variables and parameters\n",
    "col_names = ['train_cost', 'train_acc', 'val_cost', 'val_acc']\n",
    "resultsDF = pd.DataFrame(columns = col_names)\n",
    "\n",
    "epochCount = 0\n",
    "optimizer =torch.optim.Adam(myModel.parameters(), lr=0.00005)\n",
    "\n",
    "customLoss = customWeightedBCEwithLogits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset and dataloader\n",
    "preTrainDF = dataDF[dataDF['fold']==0]\n",
    "trainDF = dataDF[dataDF['fold']!=4]\n",
    "valDF = dataDF[dataDF['fold']==4]\n",
    "\n",
    "my_pretrain_dataset = Dataset(\n",
    "    dataframe= preTrainDF,\n",
    "    augmentation=get_training_augmentation(),\n",
    "    transform=data_transform,\n",
    ")\n",
    "\n",
    "my_train_dataset = Dataset(\n",
    "    dataframe= trainDF,\n",
    "    augmentation=get_training_augmentation(),\n",
    "    transform=data_transform,\n",
    ")\n",
    "\n",
    "my_val_dataset = Dataset(\n",
    "    dataframe= valDF,\n",
    "    augmentation=None,\n",
    "    transform=data_transform,\n",
    ")\n",
    "\n",
    "myPreTrainLoader = DataLoader(my_pretrain_dataset, batch_size=48, shuffle=True, num_workers=4)\n",
    "myTrainLoader = DataLoader(my_train_dataset, batch_size=42, shuffle=True, num_workers=4)\n",
    "myValidLoader = DataLoader(my_val_dataset, batch_size=42, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "\n",
    "print(my_train_dataset.__len__())\n",
    "\n",
    "oneItem = my_pretrain_dataset.__getitem__(35)\n",
    "print('label:', oneItem[1])\n",
    "print(oneItem[1].shape)\n",
    "print('image shape:', oneItem[0].shape)\n",
    "for eachInd in range(3):\n",
    "    plt.figure()\n",
    "    plt.imshow(oneItem[0][eachInd,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "\n",
    "for name, child in myModel.named_children():\n",
    "    for name2, params in child.named_parameters():\n",
    "        print('block index:', str(ind), name, name2)\n",
    "    ind = ind +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze everything except block index 9\n",
    "trainBlock = [9]\n",
    "\n",
    "ind = 0\n",
    "for name, child in myModel.named_children():\n",
    "    if ind not in trainBlock:\n",
    "        for name2, params in child.named_parameters():\n",
    "            params.requires_grad = False\n",
    "    ind = ind +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_loop(1, myModel, myPreTrainLoader, myValidLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train for 3 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = torch.load('models/CNNmodel/CNNmodel_01_epoch0_20201008_0038.pth')\n",
    "myModel.cuda()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze everything before further training\n",
    "for name, child in myModel.named_children():\n",
    "    for name2, params in child.named_parameters():\n",
    "        params.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971c774af7cd47fa81ca3f3276cc1b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d42a2925e64cb8a2a8a7a3da292cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8527.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_cost: 0.0113, train_acc: 0.9576, val_cost: 0.0102, val_acc: 0.9574\n",
      "saving:  models/CNNmodel/CNNmodel_01_epoch0_20201008_1406.pth\n",
      "epoch 1:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efe27541d07402f8b11b351271ed5f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6850e78b8994644ba78f6e3943f1c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8527.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_cost: 0.0091, train_acc: 0.9656, val_cost: 0.0105, val_acc: 0.9667\n",
      "saving:  models/CNNmodel/CNNmodel_01_epoch1_20201008_2252.pth\n",
      "epoch 2:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47437becccec4d40a3ee6e503679019b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bcf904eb1f441cf858f2c53f2996146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8527.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_cost: 0.0078, train_acc: 0.9699, val_cost: 0.0111, val_acc: 0.9628\n",
      "saving:  models/CNNmodel/CNNmodel_01_epoch2_20201009_0744.pth\n"
     ]
    }
   ],
   "source": [
    "# Train for 3 more epochs\n",
    "main_loop(3, myModel, myTrainLoader, myValidLoader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorchEnv37",
   "language": "python",
   "name": "pytorchenv37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
