{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "# Other non-PyTorch Modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20201004_0132\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "DATESTRING = now.strftime(\"%Y%m%d_%H%M\")\n",
    "print(DATESTRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF = pd.read_csv('data_fold.csv')\n",
    "dataDF = dataDF.set_index('SOPInstanceUID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>pe_present_on_image</th>\n",
       "      <th>negative_exam_for_pe</th>\n",
       "      <th>qa_motion</th>\n",
       "      <th>qa_contrast</th>\n",
       "      <th>flow_artifact</th>\n",
       "      <th>rv_lv_ratio_gte_1</th>\n",
       "      <th>rv_lv_ratio_lt_1</th>\n",
       "      <th>leftsided_pe</th>\n",
       "      <th>...</th>\n",
       "      <th>ma</th>\n",
       "      <th>exposure</th>\n",
       "      <th>img_pos</th>\n",
       "      <th>conv_kernel</th>\n",
       "      <th>patient_position</th>\n",
       "      <th>pixel_spacing</th>\n",
       "      <th>bits_stored</th>\n",
       "      <th>high_bit</th>\n",
       "      <th>img_count</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOPInstanceUID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c0f3cb036d06</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>842</td>\n",
       "      <td>108</td>\n",
       "      <td>-234.5</td>\n",
       "      <td>B30f</td>\n",
       "      <td>HFS</td>\n",
       "      <td>[0.5234375, 0.5234375]</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f57ffd3883b6</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>966</td>\n",
       "      <td>124</td>\n",
       "      <td>-252.5</td>\n",
       "      <td>B30f</td>\n",
       "      <td>HFS</td>\n",
       "      <td>[0.5234375, 0.5234375]</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41220fda34a3</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>596</td>\n",
       "      <td>76</td>\n",
       "      <td>-432.5</td>\n",
       "      <td>B30f</td>\n",
       "      <td>HFS</td>\n",
       "      <td>[0.5234375, 0.5234375]</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13b685b4b14f</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>599</td>\n",
       "      <td>76</td>\n",
       "      <td>-434.5</td>\n",
       "      <td>B30f</td>\n",
       "      <td>HFS</td>\n",
       "      <td>[0.5234375, 0.5234375]</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be0b7524ffb4</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>603</td>\n",
       "      <td>77</td>\n",
       "      <td>-436.5</td>\n",
       "      <td>B30f</td>\n",
       "      <td>HFS</td>\n",
       "      <td>[0.5234375, 0.5234375]</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               StudyInstanceUID SeriesInstanceUID  pe_present_on_image  \\\n",
       "SOPInstanceUID                                                           \n",
       "c0f3cb036d06       6897fa9de148      2bfbb7fd2e8b                    0   \n",
       "f57ffd3883b6       6897fa9de148      2bfbb7fd2e8b                    0   \n",
       "41220fda34a3       6897fa9de148      2bfbb7fd2e8b                    0   \n",
       "13b685b4b14f       6897fa9de148      2bfbb7fd2e8b                    0   \n",
       "be0b7524ffb4       6897fa9de148      2bfbb7fd2e8b                    0   \n",
       "\n",
       "                negative_exam_for_pe  qa_motion  qa_contrast  flow_artifact  \\\n",
       "SOPInstanceUID                                                                \n",
       "c0f3cb036d06                       0          0            0              0   \n",
       "f57ffd3883b6                       0          0            0              0   \n",
       "41220fda34a3                       0          0            0              0   \n",
       "13b685b4b14f                       0          0            0              0   \n",
       "be0b7524ffb4                       0          0            0              0   \n",
       "\n",
       "                rv_lv_ratio_gte_1  rv_lv_ratio_lt_1  leftsided_pe  ...   ma  \\\n",
       "SOPInstanceUID                                                     ...        \n",
       "c0f3cb036d06                    0                 1             1  ...  842   \n",
       "f57ffd3883b6                    0                 1             1  ...  966   \n",
       "41220fda34a3                    0                 1             1  ...  596   \n",
       "13b685b4b14f                    0                 1             1  ...  599   \n",
       "be0b7524ffb4                    0                 1             1  ...  603   \n",
       "\n",
       "                exposure  img_pos  conv_kernel  patient_position  \\\n",
       "SOPInstanceUID                                                     \n",
       "c0f3cb036d06         108   -234.5         B30f               HFS   \n",
       "f57ffd3883b6         124   -252.5         B30f               HFS   \n",
       "41220fda34a3          76   -432.5         B30f               HFS   \n",
       "13b685b4b14f          76   -434.5         B30f               HFS   \n",
       "be0b7524ffb4          77   -436.5         B30f               HFS   \n",
       "\n",
       "                         pixel_spacing  bits_stored  high_bit  img_count  fold  \n",
       "SOPInstanceUID                                                                  \n",
       "c0f3cb036d06    [0.5234375, 0.5234375]           12        11        124     3  \n",
       "f57ffd3883b6    [0.5234375, 0.5234375]           12        11        124     3  \n",
       "41220fda34a3    [0.5234375, 0.5234375]           12        11        124     3  \n",
       "13b685b4b14f    [0.5234375, 0.5234375]           12        11        124     3  \n",
       "be0b7524ffb4    [0.5234375, 0.5234375]           12        11        124     3  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = dataDF[dataDF['fold']!=4]\n",
    "valDF = dataDF[dataDF['fold']==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingDirPath = 'data/embeddings/expt11/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class embeddingsDataset(Dataset):\n",
    "    \"\"\"create sample dataset to work with\"\"\"\n",
    "\n",
    "    def __init__(self, dataDF = None, listOfStudies = None):\n",
    "        self.dataDF = dataDF\n",
    "        self.listOfStudies = listOfStudies\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.listOfStudies)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        embedDict = pickle.load(open(embeddingDirPath+self.listOfStudies[idx]+'.p', 'rb'))\n",
    "        embeddingVolume = np.array(embedDict['embeddings'])\n",
    "        listOfImages = embedDict['ids']\n",
    "        labels = [self.dataDF.loc[eachImageID, 'pe_present_on_image']for eachImageID in listOfImages]\n",
    "        labels = np.array(labels).astype(np.float32)\n",
    "        return embeddingVolume, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainEmbeddingsDataset = embeddingsDataset(dataDF=dataDF, listOfStudies=trainDF['StudyInstanceUID'].unique())\n",
    "trainEmbeddingsDataloader = DataLoader(trainEmbeddingsDataset, batch_size=1, shuffle=True, num_workers=1)\n",
    "\n",
    "valEmbeddingsDataset = embeddingsDataset(dataDF=dataDF, listOfStudies=valDF['StudyInstanceUID'].unique())\n",
    "valEmbeddingsDataloader = DataLoader(valEmbeddingsDataset, batch_size=1, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 64\n",
    "HIDDEN_SIZE = 32\n",
    "NUM_LAYERS = 1\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "class BiGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(BiGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.GRU = nn.GRU(\n",
    "            input_size, hidden_size, num_layers, batch_first=True, bidirectional=True\n",
    "        )\n",
    "        self.linear1 = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).cuda()\n",
    "        #c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).cuda()\n",
    "\n",
    "        out, _ = self.GRU(x, h0)\n",
    "        \n",
    "        for i, out_t in enumerate(out.chunk(out.size(1), dim=1)):\n",
    "            out_t = out_t.squeeze(1)\n",
    "            out_t = F.relu(self.linear1(out_t))\n",
    "            out_t = self.linear2(out_t)\n",
    "            outputs += [out_t]\n",
    "        outputs = torch.stack(outputs, 1).squeeze(2)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 64\n",
    "HIDDEN_SIZE = 32\n",
    "NUM_LAYERS = 1\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "class BRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(BRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, hidden_size, num_layers, batch_first=True, bidirectional=True\n",
    "        )\n",
    "        self.linear1 = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).cuda()\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).cuda()\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        for i, out_t in enumerate(out.chunk(out.size(1), dim=1)):\n",
    "            out_t = out_t.squeeze(1)\n",
    "            out_t = F.relu(self.linear1(out_t))\n",
    "            out_t = self.linear2(out_t)\n",
    "            outputs += [out_t]\n",
    "        outputs = torch.stack(outputs, 1).squeeze(2)\n",
    "        print(outputs.size())\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequence(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Sequence, self).__init__()\n",
    "        self.gru1 = nn.GRUCell(64, 32)\n",
    "        self.linear1 = nn.Linear(32, 16)\n",
    "        self.linear2 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        outputs = []\n",
    "        h_t = torch.zeros(input.size(0), 32, dtype=torch.float).cuda()\n",
    "        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):\n",
    "            input_t = input_t.squeeze(1)\n",
    "            h_t = self.gru1(input_t, h_t)\n",
    "            output = F.relu(self.linear1(h_t))\n",
    "            output = self.linear2(output)\n",
    "            outputs += [output]\n",
    "        outputs = torch.stack(outputs, 1).squeeze(2)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = BiGRU(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(3.0))\n",
    "\n",
    "optimizer = optim.Adam(seq.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_loader):\n",
    "    train_total = train_correct = train_cost = 0\n",
    "    seq.train()\n",
    "    for x,y in tqdm(train_loader):\n",
    "        x=x.cuda()\n",
    "        y=y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        o = seq(x)\n",
    "        train_total += y.size(1)\n",
    "        train_correct += ((torch.sigmoid(o[0,:])>0.5) == (y[0,:]>0.5)).sum().item()\n",
    "        loss = criterion(o, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_cost += loss.item()\n",
    "    return train_cost/train_total, train_correct/train_total\n",
    "\n",
    "def valid_loop(model, valid_loader):\n",
    "    # Evaluate on validation  data \n",
    "    val_total = val_correct = val_cost = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in tqdm(valid_loader):\n",
    "            x_val = x_val.cuda()\n",
    "            y_val = y_val.cuda()\n",
    "            o = seq(x_val)\n",
    "            val_total += y_val.size(1)\n",
    "            val_correct += ((torch.sigmoid(o[0,:])>0.5) == (y_val[0,:]>0.5)).sum().item()\n",
    "            loss = criterion(o, y_val)\n",
    "            val_cost += loss.item()\n",
    "    return val_cost/val_total, val_correct/val_total\n",
    "\n",
    "def main_loop(n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        print('epoch ' + str(epoch) + ':')\n",
    "        train_avgCost, train_acc = train_loop(seq, trainEmbeddingsDataloader)\n",
    "        val_avgCost, val_acc = valid_loop(seq, valEmbeddingsDataloader)\n",
    "        print('train_cost: %.4f, train_acc: %.4f, val_cost: %.4f, val_acc: %.4f'\\\n",
    "              % (train_avgCost, train_acc, val_avgCost, val_acc))\n",
    "        modelPath = 'models/embedderModel/ver01_epoch' + str(epoch) + '_' + DATESTRING +'.pth'\n",
    "        print('saving: ',modelPath)\n",
    "        torch.save(seq, modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5824 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5824/5824 [05:55<00:00, 16.38it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1455/1455 [00:35<00:00, 41.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_cost: 0.0004, train_acc: 0.9822, val_cost: 0.0009, val_acc: 0.9707\n",
      "saving:  models/embedderModel/ver01_epoch0_20201004_0132.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main_loop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valEmbeddingsDataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6fc6a035b7c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miterVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalEmbeddingsDataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Sanity Check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterVal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valEmbeddingsDataloader' is not defined"
     ]
    }
   ],
   "source": [
    "iterVal = iter(valEmbeddingsDataloader)\n",
    "# Sanity Check\n",
    "seq.eval()\n",
    "with torch.no_grad():\n",
    "    x,y = next(iterVal)\n",
    "    x=x.cuda()\n",
    "    y=y.cuda()\n",
    "    o = seq(x)\n",
    "    pred = torch.sigmoid(o)\n",
    "    for eachIndex in range(pred.size(1)):\n",
    "        print((pred[0,eachIndex]).type(torch.float).item(), y[0, eachIndex].item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorchEnv37",
   "language": "python",
   "name": "pytorchenv37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
