{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "# Other non-PyTorch Modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20201004_0819\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "DATESTRING = now.strftime(\"%Y%m%d_%H%M\")\n",
    "print(DATESTRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF = pd.read_csv('data_fold.csv')\n",
    "dataDF = dataDF.set_index('SOPInstanceUID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StudyInstanceUID', 'SeriesInstanceUID', 'pe_present_on_image',\n",
       "       'negative_exam_for_pe', 'qa_motion', 'qa_contrast', 'flow_artifact',\n",
       "       'rv_lv_ratio_gte_1', 'rv_lv_ratio_lt_1', 'leftsided_pe', 'chronic_pe',\n",
       "       'true_filling_defect_not_pe', 'rightsided_pe', 'acute_and_chronic_pe',\n",
       "       'central_pe', 'indeterminate', 'window_center', 'window_width',\n",
       "       'intercept', 'slope', 'slice_thickness', 'kvp', 'ma', 'exposure',\n",
       "       'img_pos', 'conv_kernel', 'patient_position', 'pixel_spacing',\n",
       "       'bits_stored', 'high_bit', 'img_count', 'fold'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF = dataDF.reindex(columns=['StudyInstanceUID', 'SeriesInstanceUID', 'pe_present_on_image', 'negative_exam_for_pe',\n",
    "                       'indeterminate', 'chronic_pe', 'acute_and_chronic_pe', 'central_pe', 'leftsided_pe',\n",
    "                       'rightsided_pe', 'rv_lv_ratio_gte_1', 'rv_lv_ratio_lt_1','fold','img_pos','patient_position',\n",
    "                       'intercept', 'slope'])                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>pe_present_on_image</th>\n",
       "      <th>negative_exam_for_pe</th>\n",
       "      <th>indeterminate</th>\n",
       "      <th>chronic_pe</th>\n",
       "      <th>acute_and_chronic_pe</th>\n",
       "      <th>central_pe</th>\n",
       "      <th>leftsided_pe</th>\n",
       "      <th>rightsided_pe</th>\n",
       "      <th>rv_lv_ratio_gte_1</th>\n",
       "      <th>rv_lv_ratio_lt_1</th>\n",
       "      <th>fold</th>\n",
       "      <th>img_pos</th>\n",
       "      <th>patient_position</th>\n",
       "      <th>intercept</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOPInstanceUID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c0f3cb036d06</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-234.5</td>\n",
       "      <td>HFS</td>\n",
       "      <td>-1024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f57ffd3883b6</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-252.5</td>\n",
       "      <td>HFS</td>\n",
       "      <td>-1024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41220fda34a3</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-432.5</td>\n",
       "      <td>HFS</td>\n",
       "      <td>-1024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13b685b4b14f</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-434.5</td>\n",
       "      <td>HFS</td>\n",
       "      <td>-1024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be0b7524ffb4</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-436.5</td>\n",
       "      <td>HFS</td>\n",
       "      <td>-1024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               StudyInstanceUID SeriesInstanceUID  pe_present_on_image  \\\n",
       "SOPInstanceUID                                                           \n",
       "c0f3cb036d06       6897fa9de148      2bfbb7fd2e8b                    0   \n",
       "f57ffd3883b6       6897fa9de148      2bfbb7fd2e8b                    0   \n",
       "41220fda34a3       6897fa9de148      2bfbb7fd2e8b                    0   \n",
       "13b685b4b14f       6897fa9de148      2bfbb7fd2e8b                    0   \n",
       "be0b7524ffb4       6897fa9de148      2bfbb7fd2e8b                    0   \n",
       "\n",
       "                negative_exam_for_pe  indeterminate  chronic_pe  \\\n",
       "SOPInstanceUID                                                    \n",
       "c0f3cb036d06                       0              0           0   \n",
       "f57ffd3883b6                       0              0           0   \n",
       "41220fda34a3                       0              0           0   \n",
       "13b685b4b14f                       0              0           0   \n",
       "be0b7524ffb4                       0              0           0   \n",
       "\n",
       "                acute_and_chronic_pe  central_pe  leftsided_pe  rightsided_pe  \\\n",
       "SOPInstanceUID                                                                  \n",
       "c0f3cb036d06                       0           0             1              1   \n",
       "f57ffd3883b6                       0           0             1              1   \n",
       "41220fda34a3                       0           0             1              1   \n",
       "13b685b4b14f                       0           0             1              1   \n",
       "be0b7524ffb4                       0           0             1              1   \n",
       "\n",
       "                rv_lv_ratio_gte_1  rv_lv_ratio_lt_1  fold  img_pos  \\\n",
       "SOPInstanceUID                                                       \n",
       "c0f3cb036d06                    0                 1     3   -234.5   \n",
       "f57ffd3883b6                    0                 1     3   -252.5   \n",
       "41220fda34a3                    0                 1     3   -432.5   \n",
       "13b685b4b14f                    0                 1     3   -434.5   \n",
       "be0b7524ffb4                    0                 1     3   -436.5   \n",
       "\n",
       "               patient_position  intercept  slope  \n",
       "SOPInstanceUID                                     \n",
       "c0f3cb036d06                HFS      -1024      1  \n",
       "f57ffd3883b6                HFS      -1024      1  \n",
       "41220fda34a3                HFS      -1024      1  \n",
       "13b685b4b14f                HFS      -1024      1  \n",
       "be0b7524ffb4                HFS      -1024      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = dataDF[dataDF['fold']!=4]\n",
    "valDF = dataDF[dataDF['fold']==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingDirPath = 'data/embeddings/expt11/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class embeddingsDataset(Dataset):\n",
    "    \"\"\"create sample dataset to work with\"\"\"\n",
    "\n",
    "    def __init__(self, dataDF = None, listOfStudies = None):\n",
    "        self.dataDF = dataDF\n",
    "        self.listOfStudies = listOfStudies\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.listOfStudies)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        embedDict = pickle.load(open(embeddingDirPath+self.listOfStudies[idx]+'.p', 'rb'))\n",
    "        embeddingVolume = np.array(embedDict['embeddings'])\n",
    "        listOfImages = embedDict['ids']\n",
    "        imageLevelLabels = [self.dataDF.loc[eachImageID, 'pe_present_on_image']for eachImageID in listOfImages]\n",
    "        imageLevelLabels = np.array(imageLevelLabels).astype(np.float32)\n",
    "        studyLevelLabels = self.dataDF.loc[listOfImages[0]][3:12].values\n",
    "        studyLevelLabels = np.array(studyLevelLabels).astype(np.float32)\n",
    "        return embeddingVolume, (imageLevelLabels, studyLevelLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainEmbeddingsDataset = embeddingsDataset(dataDF=dataDF, listOfStudies=trainDF['StudyInstanceUID'].unique())\n",
    "trainEmbeddingsDataloader = DataLoader(trainEmbeddingsDataset, batch_size=1, shuffle=True, num_workers=1)\n",
    "\n",
    "valEmbeddingsDataset = embeddingsDataset(dataDF=dataDF, listOfStudies=valDF['StudyInstanceUID'].unique())\n",
    "valEmbeddingsDataloader = DataLoader(valEmbeddingsDataset, batch_size=1, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 64\n",
    "HIDDEN_SIZE = 32\n",
    "NUM_LAYERS = 1\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "class BiGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(BiGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.GRU = nn.GRU(\n",
    "            input_size, hidden_size, num_layers, batch_first=True, bidirectional=True\n",
    "        )\n",
    "        self.linear1 = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.linear3 = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.linear4 = nn.Linear(hidden_size, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        imageLevelOutputs = []\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).cuda()\n",
    "        #c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).cuda()\n",
    "\n",
    "        out, h_n = self.GRU(x, h0)\n",
    "        \n",
    "        for i, out_t in enumerate(out.chunk(out.size(1), dim=1)):\n",
    "            out_t = out_t.squeeze(1)\n",
    "            out_t = F.relu(self.linear1(out_t))\n",
    "            out_t = self.linear2(out_t)\n",
    "            imageLevelOutputs += [out_t]\n",
    "        imageLevelOutputs = torch.stack(imageLevelOutputs, 1).squeeze(2)\n",
    "        \n",
    "        h_n = h_n.view(1,-1)\n",
    "        studyLevelOutputs = F.relu(self.linear3(h_n))\n",
    "        studyLevelOutputs = self.linear4(studyLevelOutputs)\n",
    "        \n",
    "        return (imageLevelOutputs, studyLevelOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = BiGRU(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch,seqNum,features\n",
    "sampleInput = torch.rand((1,120,64)).cuda()\n",
    "sampleImgOutput, sampleStdOutput = seq(sampleInput)\n",
    "print(sampleImgOutput.size())\n",
    "print(sampleStdOutput.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customLoss(imageLevelOutputLogits, imageLevelLabels, studyLeveloutputLogits, studyLevelLabels):\n",
    "    imageLevelLoss = F.binary_cross_entropy_with_logits(imageLevelOutputLogits,imageLevelLabels,pos_weight = torch.tensor([3.0]).cuda())\n",
    "    \n",
    "    studyLevelLoss = 0\n",
    "    weightList = [0.0736196319, 0.09202453988, 0.1042944785, 0.1042944785, 0.1877300613, 0.06257668712, 0.06257668712, 0.2346625767, 0.0782208589]\n",
    "    for eachInd in range(9):\n",
    "        studyLevelLoss = weightList[eachInd]*F.binary_cross_entropy_with_logits(studyLeveloutputLogits[:,eachInd],studyLevelLabels[:,eachInd])\n",
    "    studyLevelLoss = studyLevelLoss/9\n",
    "    \n",
    "    return imageLevelLoss+studyLevelLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(seq.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_loader):\n",
    "    train_total = train_correct = train_cost = 0\n",
    "    seq.train()\n",
    "    for x, (y_img, y_std) in tqdm(train_loader):\n",
    "        x = x.cuda()\n",
    "        y_img = y_img.cuda()\n",
    "        y_std = y_std.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        (o_img, o_std) = seq(x)\n",
    "        train_total += y_img.size(1)\n",
    "        train_correct += ((torch.sigmoid(o_img[0,:])>0.5) == (y_img[0,:]>0.5)).sum().item()\n",
    "        loss = customLoss(o_img, y_img, o_std, y_std)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_cost += loss.item()\n",
    "    return train_cost/train_total, train_correct/train_total\n",
    "\n",
    "def valid_loop(model, valid_loader):\n",
    "    # Evaluate on validation  data \n",
    "    val_total = val_correct = val_cost = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_val, (y_val_img, y_val_std) in tqdm(valid_loader):\n",
    "            x_val = x_val.cuda()\n",
    "            y_val_img = y_val_img.cuda()\n",
    "            y_val_std = y_val_std.cuda()\n",
    "            (o_val_img, o_val_std) = seq(x_val)\n",
    "            val_total += y_val_img.size(1)\n",
    "            val_correct += ((torch.sigmoid(o_val_img[0,:])>0.5) == (y_val_img[0,:]>0.5)).sum().item()\n",
    "            loss = customLoss(o_val_img, y_val_img, o_val_std, y_val_std)\n",
    "            val_cost += loss.item()\n",
    "    return val_cost/val_total, val_correct/val_total\n",
    "\n",
    "def main_loop(n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        print('epoch ' + str(epoch) + ':')\n",
    "        train_avgCost, train_acc = train_loop(seq, trainEmbeddingsDataloader)\n",
    "        val_avgCost, val_acc = valid_loop(seq, valEmbeddingsDataloader)\n",
    "\n",
    "        print('train_cost: %.4f, train_acc: %.4f, val_cost: %.4f, val_acc: %.4f'\\\n",
    "              % (train_avgCost, train_acc, val_avgCost, val_acc))\n",
    "        modelPath = 'models/embedderModel/ver01_epoch' + str(epoch) + '_' + DATESTRING +'.pth'\n",
    "        print('saving: ',modelPath)\n",
    "        torch.save(seq, modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5824 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5824/5824 [05:57<00:00, 16.28it/s]\n",
      "100%|██████████| 1455/1455 [00:36<00:00, 40.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_cost: 0.0004, train_acc: 0.9823, val_cost: 0.0008, val_acc: 0.9669\n",
      "saving:  models/embedderModel/ver01_epoch0_20201004_0819.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main_loop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterVal = iter(valEmbeddingsDataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0022380254231393337 0.0\n",
      "0.0010307265911251307 0.0\n",
      "0.0006256763590499759 0.0\n",
      "0.0004694787785410881 0.0\n",
      "0.0003717208746820688 0.0\n",
      "0.0003448638890404254 0.0\n",
      "0.0003149546100758016 0.0\n",
      "0.00031078228494152427 0.0\n",
      "0.00029557361267507076 0.0\n",
      "0.00030393333872780204 0.0\n",
      "0.0002862091059796512 0.0\n",
      "0.00028955755988135934 0.0\n",
      "0.0002866867871489376 0.0\n",
      "0.0002936552045866847 0.0\n",
      "0.0002911348710767925 0.0\n",
      "0.0002915517834480852 0.0\n",
      "0.0002899103274103254 0.0\n",
      "0.0002863283734768629 0.0\n",
      "0.00028043065685778856 0.0\n",
      "0.0002789730788208544 0.0\n",
      "0.000280115898931399 0.0\n",
      "0.00027974118711426854 0.0\n",
      "0.0002829179575201124 0.0\n",
      "0.0002830156299751252 0.0\n",
      "0.00028541425126604736 0.0\n",
      "0.00028984565869905055 0.0\n",
      "0.0002938523830380291 0.0\n",
      "0.0002886845904868096 0.0\n",
      "0.0002866930444724858 0.0\n",
      "0.0002866651921067387 0.0\n",
      "0.00029421679209917784 0.0\n",
      "0.0003001329314429313 0.0\n",
      "0.00030457816319540143 0.0\n",
      "0.000299887266010046 0.0\n",
      "0.000300497718853876 0.0\n",
      "0.0002967705950140953 0.0\n",
      "0.00030214525759220123 0.0\n",
      "0.00030818465165793896 0.0\n",
      "0.00035029149148613214 0.0\n",
      "0.00033410589094273746 0.0\n",
      "0.00033332835300825536 0.0\n",
      "0.0003393744118511677 0.0\n",
      "0.00034873589174821973 0.0\n",
      "0.0003582197241485119 0.0\n",
      "0.00036790245212614536 0.0\n",
      "0.0003908606886398047 0.0\n",
      "0.0003852444642689079 0.0\n",
      "0.0003801589773502201 0.0\n",
      "0.0003987467789556831 0.0\n",
      "0.0004005872178822756 0.0\n",
      "0.00039866584120318294 0.0\n",
      "0.0004053252632729709 0.0\n",
      "0.00040433695539832115 0.0\n",
      "0.0004015551239717752 0.0\n",
      "0.0004042446380481124 0.0\n",
      "0.0003996090963482857 0.0\n",
      "0.00040043832268565893 0.0\n",
      "0.0004078020283486694 0.0\n",
      "0.0004111511807423085 0.0\n",
      "0.00043212511809542775 0.0\n",
      "0.00041844628867693245 0.0\n",
      "0.00043225058470852673 0.0\n",
      "0.0004283754387870431 0.0\n",
      "0.00043480246677063406 0.0\n",
      "0.0004662754654418677 0.0\n",
      "0.0004370191600173712 0.0\n",
      "0.00044840810005553067 0.0\n",
      "0.00047779851593077183 0.0\n",
      "0.00046778260730206966 0.0\n",
      "0.0004652347706723958 0.0\n",
      "0.00048240282922051847 0.0\n",
      "0.0004852756392210722 0.0\n",
      "0.0005183087196201086 0.0\n",
      "0.0005741693894378841 0.0\n",
      "0.0005803217645734549 0.0\n",
      "0.0005630149389617145 0.0\n",
      "0.0005856892676092684 0.0\n",
      "0.0006431662477552891 0.0\n",
      "0.0008044837159104645 0.0\n",
      "0.0006806739838793874 0.0\n",
      "0.0006091864197514951 0.0\n",
      "0.0006602099165320396 0.0\n",
      "0.0008059726096689701 0.0\n",
      "0.0007829913520254195 0.0\n",
      "0.0008953925571404397 0.0\n",
      "0.000946995394770056 0.0\n",
      "0.0010632940102368593 0.0\n",
      "0.0020111047197133303 0.0\n",
      "0.002018324099481106 0.0\n",
      "0.002538330154493451 0.0\n",
      "0.0033846034202724695 0.0\n",
      "0.002174532739445567 0.0\n",
      "0.0027611926198005676 0.0\n",
      "0.00275836861692369 0.0\n",
      "0.004539198707789183 0.0\n",
      "0.007663597818464041 0.0\n",
      "0.02415543422102928 0.0\n",
      "0.05173635482788086 0.0\n",
      "0.026526158675551414 0.0\n",
      "0.03011513501405716 0.0\n",
      "0.01331307739019394 0.0\n",
      "0.011132028885185719 0.0\n",
      "0.014022317714989185 0.0\n",
      "0.03744561970233917 0.0\n",
      "0.02104843594133854 0.0\n",
      "0.008606425486505032 0.0\n",
      "0.005566793493926525 0.0\n",
      "0.005946667864918709 0.0\n",
      "0.005622341763228178 0.0\n",
      "0.004090911243110895 0.0\n",
      "0.004956139717251062 0.0\n",
      "0.006665131542831659 0.0\n",
      "0.007689215708523989 0.0\n",
      "0.00887587945908308 0.0\n",
      "0.00919855572283268 0.0\n",
      "0.005128977354615927 0.0\n",
      "0.0027566428761929274 0.0\n",
      "0.0023799175396561623 0.0\n",
      "0.0021568993106484413 0.0\n",
      "0.0026547028683125973 0.0\n",
      "0.00335209583863616 0.0\n",
      "0.00465134484693408 0.0\n",
      "0.0038840153720229864 0.0\n",
      "0.0045072888024151325 0.0\n",
      "0.003184325061738491 0.0\n",
      "0.0035355014260858297 0.0\n",
      "0.0033284667879343033 0.0\n",
      "0.0064559150487184525 0.0\n",
      "0.011507492512464523 0.0\n",
      "0.025410564616322517 0.0\n",
      "0.008779271505773067 0.0\n",
      "0.009646832011640072 0.0\n",
      "0.009990056976675987 0.0\n",
      "0.010045486502349377 0.0\n",
      "0.007796248886734247 0.0\n",
      "0.005227519664913416 0.0\n",
      "0.004383770748972893 0.0\n",
      "0.004316294565796852 0.0\n",
      "0.003423037240281701 0.0\n",
      "0.0030216299928724766 0.0\n",
      "0.00398053415119648 0.0\n",
      "0.005782850086688995 0.0\n",
      "0.010931056924164295 0.0\n",
      "0.012585901655256748 0.0\n",
      "0.01743338257074356 0.0\n",
      "0.017735369503498077 0.0\n",
      "0.012794343754649162 0.0\n",
      "0.022837858647108078 0.0\n",
      "0.07189759612083435 0.0\n",
      "0.023475393652915955 0.0\n",
      "0.02112511359155178 0.0\n",
      "0.03607286512851715 0.0\n",
      "0.035833097994327545 0.0\n",
      "0.06015479192137718 0.0\n",
      "0.02374815195798874 0.0\n",
      "0.016203047707676888 0.0\n",
      "0.03287140280008316 0.0\n",
      "0.04257143661379814 0.0\n",
      "0.05470215529203415 0.0\n",
      "0.054924365133047104 0.0\n",
      "0.06667953729629517 0.0\n",
      "0.09740690886974335 0.0\n",
      "0.13986064493656158 0.0\n",
      "0.14770397543907166 0.0\n",
      "0.11083260923624039 0.0\n",
      "0.10195549577474594 0.0\n",
      "0.11310358345508575 0.0\n",
      "0.09485497325658798 0.0\n",
      "0.041765280067920685 0.0\n",
      "0.044667359441518784 0.0\n",
      "0.02952287159860134 0.0\n",
      "0.030080629512667656 0.0\n",
      "0.04526301473379135 0.0\n",
      "0.025170370936393738 0.0\n",
      "0.010808823630213737 0.0\n",
      "0.01046487782150507 0.0\n",
      "0.009345103986561298 0.0\n",
      "0.0097039844840765 0.0\n",
      "0.02742425724864006 0.0\n",
      "0.03969217836856842 0.0\n",
      "0.023175859823822975 0.0\n",
      "0.00561534846201539 0.0\n",
      "0.005860691424459219 0.0\n",
      "0.0037568360567092896 0.0\n",
      "0.0038205140735954046 0.0\n",
      "0.004430373664945364 0.0\n",
      "0.011642971076071262 0.0\n",
      "0.00592518225312233 0.0\n",
      "0.007607273757457733 0.0\n",
      "0.005247949622571468 0.0\n",
      "0.004092104267328978 0.0\n",
      "0.003072459017857909 0.0\n",
      "0.002506514545530081 0.0\n",
      "0.0020246838685125113 0.0\n",
      "0.001526534091681242 0.0\n",
      "0.0018769956659525633 0.0\n",
      "0.0021954933181405067 0.0\n",
      "0.001326171332038939 0.0\n",
      "0.000891807081643492 0.0\n",
      "0.0007605292485095561 0.0\n",
      "0.0007466406677849591 0.0\n",
      "0.0007765290210954845 0.0\n",
      "0.0008798245689831674 0.0\n",
      "0.0007357403519563377 0.0\n",
      "0.0007374865235760808 0.0\n",
      "0.000665422878228128 0.0\n",
      "0.0007926332182250917 0.0\n",
      "0.0007575592026114464 0.0\n",
      "0.0005661883042193949 0.0\n",
      "0.0006014574319124222 0.0\n",
      "0.0005672172992490232 0.0\n",
      "0.0005267050000838935 0.0\n",
      "0.0005118115805089474 0.0\n",
      "0.000501355854794383 0.0\n",
      "0.0005300230113789439 0.0\n",
      "0.00047539256047457457 0.0\n",
      "0.0004118052893318236 0.0\n",
      "0.000448578066425398 0.0\n",
      "0.0003431941440794617 0.0\n",
      "0.00034114037407562137 0.0\n",
      "0.0003419597342144698 0.0\n",
      "0.00035055220359936357 0.0\n",
      "0.0003129092510789633 0.0\n",
      "0.00031253296765498817 0.0\n",
      "0.0002929326437879354 0.0\n",
      "0.00033207546221092343 0.0\n",
      "0.000346824323059991 0.0\n",
      "0.0003395061066839844 0.0\n",
      "0.0004806306678801775 0.0\n",
      "0.00036165310302749276 0.0\n",
      "0.00033762725070118904 0.0\n",
      "0.0003192574658896774 0.0\n",
      "0.0003362512798048556 0.0\n",
      "0.00029589279438368976 0.0\n",
      "0.0003202488296665251 0.0\n",
      "0.00036408432060852647 0.0\n",
      "0.0003275977214798331 0.0\n",
      "0.00035056742490269244 0.0\n",
      "0.0004635177319869399 0.0\n",
      "0.00044512609019875526 0.0\n",
      "0.0005689827958121896 0.0\n",
      "0.0006101862527430058 0.0\n",
      "0.0006866234471090138 0.0\n",
      "0.0005369003629311919 0.0\n",
      "0.0005331787979230285 0.0\n",
      "0.000550720258615911 0.0\n",
      "0.0004138363292440772 0.0\n",
      "0.0004590200842358172 0.0\n",
      "0.0004429777036421001 0.0\n",
      "0.0003842719306703657 0.0\n",
      "0.00034841219894587994 0.0\n",
      "0.0003137974126730114 0.0\n",
      "0.00032933158217929304 0.0\n",
      "0.0004295854887459427 0.0\n",
      "0.00038810737896710634 0.0\n",
      "0.0003600258787628263 0.0\n",
      "0.00031359042623080313 0.0\n",
      "0.00030488058109767735 0.0\n",
      "0.000297750870231539 0.0\n",
      "0.0002742647775448859 0.0\n",
      "0.0002777466725092381 0.0\n",
      "0.00029677312704734504 0.0\n",
      "0.00030278973281383514 0.0\n",
      "0.00028035021387040615 0.0\n",
      "0.0002896025835070759 0.0\n",
      "0.0002873281482607126 0.0\n",
      "0.00028052477864548564 0.0\n",
      "0.0002814986801240593 0.0\n",
      "0.0002789118734654039 0.0\n",
      "0.00028704231954179704 0.0\n",
      "0.0002870056196115911 0.0\n",
      "0.0002917494857683778 0.0\n",
      "0.0002994307433255017 0.0\n",
      "0.0003148204123135656 0.0\n",
      "0.00033191023976542056 0.0\n",
      "0.000365653628250584 0.0\n",
      "0.0004811543913092464 0.0\n",
      "0.0011426530545577407 0.0\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check\n",
    "seq.eval()\n",
    "with torch.no_grad():\n",
    "    x,(y_img, _) = next(iterVal)\n",
    "    x=x.cuda()\n",
    "    o_img, _ = seq(x)\n",
    "    pred = torch.sigmoid(o_img)\n",
    "    for eachIndex in range(pred.size(1)):\n",
    "        print((pred[0,eachIndex]).type(torch.float).item(), y_img[0, eachIndex].item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorchEnv37",
   "language": "python",
   "name": "pytorchenv37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
