{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "# Other non-PyTorch Modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "\n",
    "import pydicom\n",
    "from pydicom import dcmread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataDF = pd.read_csv('test.csv', dtype={'StudyInstanceUID':'string', 'SeriesInstanceUID':'string', 'SOPInstanceUID':'string'})\n",
    "testDataDF = testDataDF.set_index('SOPInstanceUID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StringArray>\n",
      "['df06fad17bc3', 'c8039e7f9e63', '761f6f1a9f5b', 'c8db5b1f6b56',\n",
      " '462e805da1f1', '7f6fb39566ed', 'b44cbf5371f2', '62dfc5f411e8',\n",
      " '1870d65d0f6a', '26135e3b3b30',\n",
      " ...\n",
      " 'f84e2070f8fa', 'f7d667111876', 'e47f788d8c1c', '45ccc170506e',\n",
      " '9a98258fc668', '66fb5816ac72', '4ec6107512ec', '1c30b47fddbe',\n",
      " 'daa9f40349cf', '84a57a6bc1b4']\n",
      "Length: 650, dtype: string\n"
     ]
    }
   ],
   "source": [
    "listOfStudyIDs = testDataDF['StudyInstanceUID'].unique()\n",
    "print(listOfStudyIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(img, WL=50, WW=350):\n",
    "    upper, lower = WL+WW//2, WL-WW//2\n",
    "    X = np.clip(img.copy(), lower, upper)\n",
    "    X = X - np.min(X)\n",
    "    X = X / np.max(X)\n",
    "    X = (X*255.0).astype('uint8')\n",
    "    return X\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 64\n",
    "HIDDEN_SIZE = 32\n",
    "NUM_LAYERS = 1\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "class BiGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout = 0.1):\n",
    "        super(BiGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.GRU = nn.GRU(\n",
    "            input_size, hidden_size, num_layers, batch_first=True, bidirectional=True\n",
    "        )\n",
    "        self.dropout = dropout\n",
    "        self.linear1 = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.linear3 = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.linear4 = nn.Linear(hidden_size, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        imageLevelOutputs = []\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).cuda()\n",
    "        #c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).cuda()\n",
    "\n",
    "        out, h_n = self.GRU(x, h0)\n",
    "        \n",
    "        for i, out_t in enumerate(out.chunk(out.size(1), dim=1)):\n",
    "            out_t = out_t.squeeze(1)\n",
    "            out_t = F.relu(self.linear1(out_t))\n",
    "            out_t = F.dropout(out_t, p=self.dropout)\n",
    "            out_t = self.linear2(out_t)\n",
    "            imageLevelOutputs += [out_t]\n",
    "        imageLevelOutputs = torch.stack(imageLevelOutputs, 1).squeeze(2)\n",
    "        \n",
    "        h_n = h_n.view(1,-1)\n",
    "        studyLevelOutputs = F.relu(self.linear3(h_n))\n",
    "        studyLevelOutputs = F.dropout(studyLevelOutputs, p=self.dropout)\n",
    "        studyLevelOutputs = self.linear4(studyLevelOutputs)\n",
    "        \n",
    "        return (imageLevelOutputs, studyLevelOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiGRU(\n",
       "  (GRU): GRU(64, 32, batch_first=True, bidirectional=True)\n",
       "  (linear1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (linear2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (linear3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (linear4): Linear(in_features=32, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('models/CNNmodel/CNNmodel_01_epoch1_20201005_1533_embedder.pth')\n",
    "model.eval()\n",
    "\n",
    "seq = torch.load('models/embedderModel/ver03_epoch0_20201006_2004.pth')\n",
    "seq.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultScore = {'_pe_present_on_image': 0.053915069524414806,\n",
    "                 '_negative_exam_for_pe': 0.6763928618101033,\n",
    "                 '_rv_lv_ratio_gte_1': 0.12875001256566257,\n",
    "                 '_rv_lv_ratio_lt_1': 0.17437230326919448,\n",
    "                 '_leftsided_pe': 0.21089872969528548,\n",
    "                 '_chronic_pe': 0.040139752506710064,\n",
    "                 '_rightsided_pe': 0.2575653665766779,\n",
    "                 '_acute_and_chronic_pe': 0.019458347341720122,\n",
    "                 '_central_pe': 0.054468517151291695,\n",
    "                 '_indeterminate': 0.020484822355039723}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 650/650 [1:06:40<00:00,  6.15s/it]\n"
     ]
    }
   ],
   "source": [
    "def sortByImgPosHelper(EmbeddingDict):\n",
    "    return EmbeddingDict['img_pos']\n",
    "\n",
    "f = open('submissionWithStudyLabels.csv', 'w')\n",
    "f.write('id,label\\n')\n",
    "\n",
    "for eachStudyID in tqdm(listOfStudyIDs):\n",
    "    eachStudyDF = testDataDF[testDataDF['StudyInstanceUID']==eachStudyID]\n",
    "    listOfImageIDs = eachStudyDF.index.to_list()\n",
    "    \n",
    "    listOfEmbeddingDict = []\n",
    "    for eachImageID in listOfImageIDs:\n",
    "        thisImagePath = 'data/test/'+eachStudyID+'/'+eachStudyDF.loc[eachImageID,'SeriesInstanceUID']+'/'+eachImageID+'.dcm'\n",
    "        dcm_data = pydicom.read_file(thisImagePath)\n",
    "        image = dcm_data.pixel_array * int(dcm_data.RescaleSlope) + int(dcm_data.RescaleIntercept)\n",
    "        image = np.stack([window(image, WL=-600, WW=1500),\n",
    "                          window(image, WL=40, WW=400),\n",
    "                          window(image, WL=100, WW=700)], 2)\n",
    "        image = image.astype(np.float32)\n",
    "        image = data_transform(image)\n",
    "        \n",
    "        image = image.cuda()\n",
    "        toPred = image.unsqueeze(0)\n",
    "        embedding = model(toPred)\n",
    "        embedding = embedding.detach().cpu().numpy()[0]\n",
    "        \n",
    "        img_pos = dcm_data[0x20, 0x32].value[2]\n",
    "        listOfEmbeddingDict.append({'imageID':eachImageID, 'img_pos':img_pos, 'embedding':embedding})\n",
    "        \n",
    "    listOfEmbeddingDict.sort(key=sortByImgPosHelper, reverse=True)\n",
    "    embeddingVolume = [eachEmbeddingDict['embedding'] for eachEmbeddingDict in listOfEmbeddingDict]\n",
    "    embeddingVolume = np.array(embeddingVolume)\n",
    "    embeddingVolume = torch.tensor(embeddingVolume).unsqueeze(0).cuda()\n",
    "    o_img, o_std = seq(embeddingVolume)\n",
    "    pred_img = torch.sigmoid(o_img).squeeze(0).cpu().detach().numpy()\n",
    "    pred_std = torch.sigmoid(o_std).squeeze(0).cpu().detach().numpy()\n",
    "    \n",
    "    sortedListOfImageIDs = [eachEmbeddingDict['imageID'] for eachEmbeddingDict in listOfEmbeddingDict]\n",
    "    for eachIndex, eachImageID in enumerate(sortedListOfImageIDs):\n",
    "        f.write(eachImageID+','+str(pred_img[eachIndex])+'\\n')\n",
    "        \n",
    "    # Study level labels\n",
    "    listOfMetricLabels = ['_negative_exam_for_pe', '_indeterminate', '_chronic_pe', '_acute_and_chronic_pe', '_central_pe', '_leftsided_pe', '_rightsided_pe', '_rv_lv_ratio_gte_1', '_rv_lv_ratio_lt_1']\n",
    "\n",
    "    for eachIndex, eachMetric in enumerate(listOfMetricLabels):\n",
    "        f.write(eachStudyID+eachMetric+','+str(pred_std[eachIndex])+'\\n')\n",
    "\n",
    "f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "seq.eval()\n",
    "with torch.no_grad():\n",
    "    x,(y_img, _) = next(iterVal)\n",
    "    x=x.cuda()\n",
    "    o_img, _ = seq(x)\n",
    "    pred = torch.sigmoid(o_img)\n",
    "    for eachIndex in range(pred.size(1)):\n",
    "        print((pred[0,eachIndex]).type(torch.float).item(), y_img[0, eachIndex].item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorchEnv37",
   "language": "python",
   "name": "pytorchenv37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
