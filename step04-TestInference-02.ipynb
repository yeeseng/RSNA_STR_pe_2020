{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import datetime\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import pydicom\n",
    "from pydicom import dcmread\n",
    "from tqdm import tqdm\n",
    "\n",
    "startTime = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes from this cell are adopted from Quadcore/Richard Epstein public notebook\n",
    "# This notebook loads GDCM without Internet access.\n",
    "# GDCM is needed to read some DICOM compressed images.\n",
    "# Once you run a notebook and get the GDCM error, you must restart that Kernel to read the files, even if you load the GDCM software.\n",
    "# Note that you do not \"import GDCM\". You just \"import pydicom\".\n",
    "# The Dataset (gdcm-conda-install) was provided by Ronaldo S.A. Batista. Definitely deserves an upvote!\n",
    "\n",
    "!cp ../input/gdcm-conda-install/gdcm.tar .\n",
    "!tar -xvzf gdcm.tar\n",
    "!conda install --offline ./gdcm/gdcm-2.8.9-py37h71b2a6d_0.tar.bz2\n",
    "\n",
    "print(\"GDCM installed.\")\n",
    "\n",
    "import pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOPInstanceUID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c3163725fcf6</th>\n",
       "      <td>df06fad17bc3</td>\n",
       "      <td>857e3d760445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d54a8daaf836</th>\n",
       "      <td>df06fad17bc3</td>\n",
       "      <td>857e3d760445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bdc531b699cd</th>\n",
       "      <td>df06fad17bc3</td>\n",
       "      <td>857e3d760445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9e6a68e27df0</th>\n",
       "      <td>df06fad17bc3</td>\n",
       "      <td>857e3d760445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25e3307ba7da</th>\n",
       "      <td>df06fad17bc3</td>\n",
       "      <td>857e3d760445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               StudyInstanceUID SeriesInstanceUID\n",
       "SOPInstanceUID                                   \n",
       "c3163725fcf6       df06fad17bc3      857e3d760445\n",
       "d54a8daaf836       df06fad17bc3      857e3d760445\n",
       "bdc531b699cd       df06fad17bc3      857e3d760445\n",
       "9e6a68e27df0       df06fad17bc3      857e3d760445\n",
       "25e3307ba7da       df06fad17bc3      857e3d760445"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataDF = pd.read_csv('test.csv', dtype={'StudyInstanceUID':'string', 'SeriesInstanceUID':'string', 'SOPInstanceUID':'string'})\n",
    "testDataDF = testDataDF.set_index('SOPInstanceUID')\n",
    "testDataDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650\n"
     ]
    }
   ],
   "source": [
    "listOfStudyID = testDataDF['StudyInstanceUID'].unique()\n",
    "print(len(listOfStudyID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def window(img, WL=50, WW=350):\n",
    "    upper, lower = WL+WW//2, WL-WW//2\n",
    "    X = np.clip(img.copy(), lower, upper)\n",
    "    X = X - np.min(X)\n",
    "    X = X / np.max(X)\n",
    "    X = (X*255.0).astype('uint8')\n",
    "    return X\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# Helper functions for inference\n",
    "def dcmDataToImage(dcmData):\n",
    "    image = dcmData.pixel_array * int(dcmData.RescaleSlope) + int(dcmData.RescaleIntercept)\n",
    "    image = np.stack([window(image, WL=-600, WW=1500),\n",
    "                    window(image, WL=40, WW=400),\n",
    "                    window(image, WL=100, WW=700)], 2)\n",
    "    #image = image.astype(np.float32)\n",
    "    return image\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "def sortByImgPosHelper(dcmDataDict):\n",
    "    return dcmDataDict['img_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 64\n",
    "HIDDEN_SIZE = 32\n",
    "NUM_LAYERS = 1\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "class BiGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(BiGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.GRU = nn.GRU(\n",
    "            input_size, hidden_size, num_layers, batch_first=True, bidirectional=True\n",
    "        )\n",
    "        self.linear1 = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.linear3 = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.linear4 = nn.Linear(hidden_size, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        imageLevelOutputs = []\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).cuda()\n",
    "        #c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).cuda()\n",
    "\n",
    "        out, h_n = self.GRU(x, h0)\n",
    "        \n",
    "        for i, out_t in enumerate(out.chunk(out.size(1), dim=1)):\n",
    "            out_t = out_t.squeeze(1)\n",
    "            out_t = F.relu(self.linear1(out_t))\n",
    "            out_t = self.linear2(out_t)\n",
    "            imageLevelOutputs += [out_t]\n",
    "        imageLevelOutputs = torch.stack(imageLevelOutputs, 1).squeeze(2)\n",
    "        \n",
    "        h_n = h_n.view(1,-1)\n",
    "        studyLevelOutputs = F.relu(self.linear3(h_n))\n",
    "        studyLevelOutputs = self.linear4(studyLevelOutputs)\n",
    "        \n",
    "        return (imageLevelOutputs, studyLevelOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNmodel_Path = 'models/CNNmodel/CNNmodel_01_epoch1_CV4_20201008_2252_embedder.pth' \n",
    "CNNembedderModel = torch.load(CNNmodel_Path) \n",
    "CNNembedderModel.eval();\n",
    "\n",
    "RNNmodel_Path = 'models/embedderModel/CNNmodel_01_epoch1_CV4_20201008_2252_sequence3_20201012_1953.pth'\n",
    "RNNmodel = torch.load(RNNmodel_Path) \n",
    "RNNmodel.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study level labels\n",
    "listOfMetricLabels = ['_negative_exam_for_pe', '_indeterminate',\n",
    "                        '_chronic_pe', '_acute_and_chronic_pe',\n",
    "                        '_central_pe', '_leftsided_pe', '_rightsided_pe',\n",
    "                        '_rv_lv_ratio_gte_1', '_rv_lv_ratio_lt_1']\n",
    "\n",
    "defaultScore = {'_pe_present_on_image': 0.053915069524414806,\n",
    "                 '_negative_exam_for_pe': 0.6763928618101033,\n",
    "                 '_rv_lv_ratio_gte_1': 0.12875001256566257,\n",
    "                 '_rv_lv_ratio_lt_1': 0.17437230326919448,\n",
    "                 '_leftsided_pe': 0.21089872969528548,\n",
    "                 '_chronic_pe': 0.040139752506710064,\n",
    "                 '_rightsided_pe': 0.2575653665766779,\n",
    "                 '_acute_and_chronic_pe': 0.019458347341720122,\n",
    "                 '_central_pe': 0.054468517151291695,\n",
    "                 '_indeterminate': 0.020484822355039723}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 650/650 [32:20<00:00,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('submissionNew02.csv', 'w')\n",
    "f.write('id,label\\n')\n",
    "\n",
    "pred = 0.5\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for eachStudyID in tqdm(listOfStudyID):\n",
    "        \n",
    "        thisStudyDF = testDataDF[testDataDF['StudyInstanceUID']==eachStudyID]\n",
    "        listOfImageIDs = thisStudyDF.index\n",
    "        \n",
    "        try: \n",
    "            listOfDcm_dataDict = []\n",
    "            for eachImageID in listOfImageIDs:\n",
    "                eachImagePath = 'data/test/'+testDataDF.loc[eachImageID, 'StudyInstanceUID']+'/'+testDataDF.loc[eachImageID, 'SeriesInstanceUID']+'/'+eachImageID+'.dcm'\n",
    "                dcm_data = dcmread(eachImagePath)\n",
    "                img_pos = dcm_data[0x20, 0x32].value[2]\n",
    "                listOfDcm_dataDict.append({'imageID':eachImageID, 'dcm_data':dcm_data, 'img_pos':img_pos})\n",
    "\n",
    "            listOfDcm_dataDict.sort(key=sortByImgPosHelper, reverse=True)\n",
    "\n",
    "            tensorChunkIterator = chunks(listOfDcm_dataDict,36)\n",
    "\n",
    "            embeddingList = []\n",
    "            for eachChunk in tensorChunkIterator:\n",
    "                images = [dcmDataToImage(eachImageID['dcm_data']) for eachImageID in eachChunk]\n",
    "                images = [eachImage.astype(np.float32) for eachImage in images]\n",
    "                listOfTensors = [data_transform(eachImage) for eachImage in images]\n",
    "                stackedImagesTensor = torch.stack(listOfTensors, dim=0, out=None)\n",
    "                stackedImagesTensor = stackedImagesTensor.cuda()\n",
    "                embedding = CNNembedderModel(stackedImagesTensor)\n",
    "                embeddingList.append(embedding)\n",
    "\n",
    "            embeddingVol = torch.cat(embeddingList, dim=0)\n",
    "            embeddingVol = embeddingVol.unsqueeze(0)\n",
    "\n",
    "            imageLevelLabels, studyLevelLabels = RNNmodel(embeddingVol)\n",
    "            imageLevelLabels = torch.sigmoid(imageLevelLabels).squeeze(0).cpu().detach().numpy()\n",
    "            studyLevelLabels = torch.sigmoid(studyLevelLabels).squeeze(0).cpu().detach().numpy()\n",
    "\n",
    "            # imageLevelLabels\n",
    "            for eachIndex in range(len(listOfDcm_dataDict)):\n",
    "                f.write(listOfDcm_dataDict[eachIndex]['imageID']+','+str(imageLevelLabels[eachIndex])+'\\n')\n",
    "\n",
    "            # studyLevelLavels\n",
    "            for eachIndex, eachMetric in enumerate(listOfMetricLabels):\n",
    "                f.write(eachStudyID+eachMetric+','+str(studyLevelLabels[eachIndex])+'\\n')\n",
    "        except:\n",
    "            # imageLevelLabels\n",
    "            for eachImageID in listOfImageIDs:\n",
    "                f.write(eachImageID+','+str(defaultScore['_pe_present_on_image'])+'\\n')\n",
    "\n",
    "            # studyLevelLavels\n",
    "            for eachIndex, eachMetric in enumerate(listOfMetricLabels):\n",
    "                f.write(eachStudyID+eachMetric+','+str(defaultScore[eachMetric])+'\\n')\n",
    "            \n",
    "f.close()\n",
    "\n",
    "print('finish')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorchEnv37",
   "language": "python",
   "name": "pytorchenv37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
